# -*- coding: utf-8 -*-
"""soya_modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uP8SYCBHsmhcOnueh__fUBCp-oEfyvZw

# Soy blossom period prediction model

## Setup

### Configure environment
"""

!pip install pydot

"""### Show the machine details the environment is running on

Show CPU info
"""

!cat /proc/cpuinfo

"""Show RAM info"""

!cat /proc/meminfo

"""Show GPU info"""

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

"""### Import modules"""

from matplotlib import cm
from matplotlib import gridspec
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from sklearn import metrics
import random

import tensorflow as tf
import keras
from sklearn.metrics import r2_score as r2_metric
from keras import optimizers
from keras import backend as K

def r2(y_true, y_pred):
    SS_res =  K.sum(K.square( y_true-y_pred )) 
    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) 
    return ( 1 - SS_res/(SS_tot + K.epsilon()) )

"""### Set up the dataset

Download a dataset from shared Drive folder.
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#2. Get the file
downloaded = drive.CreateFile({'id':'1OIQG0qbmaaXUKWvYKenbI9CxekUkkUET'})
downloaded.GetContentFile('soydata.csv')

"""Import data set into pandas dataframe. The dataset contains a missing value on one of the key features the model will be training with, so we need to remove that explicitly"""

df = pd.read_csv('soydata.csv', index_col=[0, 1], prefix='Experiment')
df.dropna()
df.head(5)

"""The data in now loaded, it uses format that will be described somewhere here some day.

### Feature extraction

Shuffle the data. As dataset uses multiindex that is a little tricky, we need to shuffle only the certain level, but the days inside a single experiment shall be in natural order.
"""

shuffled_indexes = [i for i in range(len(df.index.levels[0]))]
random.shuffle(shuffled_indexes)
new_indexes = sorted(df.index, key=lambda x: shuffled_indexes.index(x[0]))

df = df.reindex(new_indexes)

df.head(5)

"""Select features and target parameter. As the data is shuffled at this point we no longer need multi-index, and selecting values will truncate that information automatically."""

features = ['t_min', 't_max', 'dlen', 'day']
data = df[features].values
target = df['state'].values

"""data is numpy matrix with only the needed features for the model and target is numpy vector with output data"""

#@title Select number of rows to display { run: "auto", form-width: "30%" }
num_entries = 3 #@param {type:"slider", min:0, max:5, step:1}
print("Data:  ", data.shape, "Showing only", num_entries, "\n", data[0:num_entries], "\n")
print("Target:", target.shape, "Showing only", num_entries, "\n", target[0:num_entries], "\n")

"""Split the data for training and testing"""

#@title Set the desired partition of test and train samples { run: "auto", form-width: "30%", display-mode: "both" }
border = 6100 #@param {type:"slider", min:4000, max:6100, step:30}
train_input, train_output = data[:border], target[:border]
test_input, test_output = data[border:], target[border:]

print("Train set contains", len(train_input))
print("Test set contains", len(test_input))

"""##  Model

We will use a simple model with input layer of 4 neurons, a single hidden layer with 20 neurons and 1 output neuron

### Keras model definition
"""

model = keras.Sequential()
model.add(keras.layers.Dense(20, input_dim=4, activation=tf.nn.sigmoid))
model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))

"""### Keras model compile"""

sgd = optimizers.SGD(lr=10.06)

model.compile(loss='mse',
              optimizer=sgd,
              metrics=['mse', 'mae'])

"""Model summary shows the architecture of the keras model"""

print(model.summary())

"""## Results"""

#@title Hyperparameters { run: "auto", form-width: "30%" }
epochs = 15 #@param {type:"integer"}
history = model.fit(
    train_input, train_output,
    epochs=epochs,
    verbose=1,
    batch_size=25,
    validation_split=0.01)

loss, mse, mae = model.evaluate(test_input, test_output)

print("MSE: ", mse)
print("MAE: ", mae)
# print("R2:  ", r2_value)
print("Loss:", loss)

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.show()

"""## Save model for future use

Model can be saved and then loaded to work in different environment
"""

model.save('soy_blossum_model.h5')

"""Model stores as serialized executable object, can be loaded and instanciated on the fly to exactly the same model. There are some restrictions on such saving method though. If you use this method you can only use keras api and do not include custom code, metrics for instance, that is a pitty because keras doesn't have a standart R^2 metric implementation, thus cannot be saved to be loaded without recompilation."""

del model

from keras.models import load_model

model = load_model('soy_blossum_model.h5')

"""## Evaluating difference in predicted states on actual blossum dates

Filter data so that it only has dates with actual blossum, 'day' field is defined so that it is calendar dates mapped into [0;1] interval so selecting blossum dates is easy as selecting rows where 'day' == 1
"""

blossum_dates_dataset = df.loc[df['day'] == 1.0]

blossum_dates_dataset.head(5)

predicted_blossum = model.predict(blossum_dates_dataset[features].values)

predicted_blossum

"""We can only observe the difference in state, because none of the inputs produce state >= 1, so that it is impossible to observe the difference in days without analytical or numerical extrapolation of model predictive function"""

diff_state = predicted_blossum - blossum_dates_dataset['state'].values

diff_state

print("Mean", np.mean(diff_state))
print("Std", np.std(diff_state))

"""In ideal case we want the model expected value be exactly equal to actual predicted blossum dates"""

plt.plot([x for x in range(len(predicted_blossum))], predicted_blossum)
plt.plot([x for x in range(len(blossum_dates_dataset['state'].values))], blossum_dates_dataset['state'].values)

"""## Conclusion

The model passed proof of concept phase, it does learn and gives OK prediction, more data will lead to even more accurate results.
"""